{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module torch.utils.data.dataset in torch.utils.data:\n",
      "\n",
      "NAME\n",
      "    torch.utils.data.dataset\n",
      "\n",
      "CLASSES\n",
      "    typing.Generic(builtins.object)\n",
      "        Dataset\n",
      "            ConcatDataset\n",
      "            IterableDataset\n",
      "                ChainDataset\n",
      "            Subset\n",
      "            TensorDataset\n",
      "    \n",
      "    class ChainDataset(IterableDataset)\n",
      "     |  ChainDataset(datasets: Iterable[torch.utils.data.dataset.Dataset]) -> None\n",
      "     |  \n",
      "     |  Dataset for chaining multiple :class:`IterableDataset` s.\n",
      "     |  \n",
      "     |  This class is useful to assemble different existing dataset streams. The\n",
      "     |  chaining operation is done on-the-fly, so concatenating large-scale\n",
      "     |  datasets with this class will be efficient.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      datasets (iterable of IterableDataset): datasets to be chained together\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ChainDataset\n",
      "     |      IterableDataset\n",
      "     |      Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, datasets: Iterable[torch.utils.data.dataset.Dataset]) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from IterableDataset:\n",
      "     |  \n",
      "     |  __add__(self, other: torch.utils.data.dataset.Dataset[+T_co])\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from IterableDataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (torch.utils.data.dataset.Dataset[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Dataset:\n",
      "     |  \n",
      "     |  __getitem__(self, index) -> +T_co\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class ConcatDataset(Dataset)\n",
      "     |  ConcatDataset(datasets: Iterable[torch.utils.data.dataset.Dataset]) -> None\n",
      "     |  \n",
      "     |  Dataset as a concatenation of multiple datasets.\n",
      "     |  \n",
      "     |  This class is useful to assemble different existing datasets.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      datasets (sequence): List of datasets to be concatenated\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ConcatDataset\n",
      "     |      Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, idx)\n",
      "     |  \n",
      "     |  __init__(self, datasets: Iterable[torch.utils.data.dataset.Dataset]) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  cumsum(sequence)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  cummulative_sizes\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {'cumulative_sizes': typing.List[int], 'datasets': t...\n",
      "     |  \n",
      "     |  __orig_bases__ = (torch.utils.data.dataset.Dataset[+T_co],)\n",
      "     |  \n",
      "     |  __parameters__ = (+T_co,)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class Dataset(typing.Generic)\n",
      "     |  An abstract class representing a :class:`Dataset`.\n",
      "     |  \n",
      "     |  All datasets that represent a map from keys to data samples should subclass\n",
      "     |  it. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a\n",
      "     |  data sample for a given key. Subclasses could also optionally overwrite\n",
      "     |  :meth:`__len__`, which is expected to return the size of the dataset by many\n",
      "     |  :class:`~torch.utils.data.Sampler` implementations and the default options\n",
      "     |  of :class:`~torch.utils.data.DataLoader`.\n",
      "     |  \n",
      "     |  .. note::\n",
      "     |    :class:`~torch.utils.data.DataLoader` by default constructs a index\n",
      "     |    sampler that yields integral indices.  To make it work with a map-style\n",
      "     |    dataset with non-integral indices/keys, a custom sampler must be provided.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  __getitem__(self, index) -> +T_co\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  __parameters__ = (+T_co,)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class IterableDataset(Dataset)\n",
      "     |  An iterable Dataset.\n",
      "     |  \n",
      "     |  All datasets that represent an iterable of data samples should subclass it.\n",
      "     |  Such form of datasets is particularly useful when data come from a stream.\n",
      "     |  \n",
      "     |  All subclasses should overwrite :meth:`__iter__`, which would return an\n",
      "     |  iterator of samples in this dataset.\n",
      "     |  \n",
      "     |  When a subclass is used with :class:`~torch.utils.data.DataLoader`, each\n",
      "     |  item in the dataset will be yielded from the :class:`~torch.utils.data.DataLoader`\n",
      "     |  iterator. When :attr:`num_workers > 0`, each worker process will have a\n",
      "     |  different copy of the dataset object, so it is often desired to configure\n",
      "     |  each copy independently to avoid having duplicate data returned from the\n",
      "     |  workers. :func:`~torch.utils.data.get_worker_info`, when called in a worker\n",
      "     |  process, returns information about the worker. It can be used in either the\n",
      "     |  dataset's :meth:`__iter__` method or the :class:`~torch.utils.data.DataLoader` 's\n",
      "     |  :attr:`worker_init_fn` option to modify each copy's behavior.\n",
      "     |  \n",
      "     |  Example 1: splitting workload across all workers in :meth:`__iter__`::\n",
      "     |  \n",
      "     |      >>> class MyIterableDataset(torch.utils.data.IterableDataset):\n",
      "     |      ...     def __init__(self, start, end):\n",
      "     |      ...         super(MyIterableDataset).__init__()\n",
      "     |      ...         assert end > start, \"this example code only works with end >= start\"\n",
      "     |      ...         self.start = start\n",
      "     |      ...         self.end = end\n",
      "     |      ...\n",
      "     |      ...     def __iter__(self):\n",
      "     |      ...         worker_info = torch.utils.data.get_worker_info()\n",
      "     |      ...         if worker_info is None:  # single-process data loading, return the full iterator\n",
      "     |      ...             iter_start = self.start\n",
      "     |      ...             iter_end = self.end\n",
      "     |      ...         else:  # in a worker process\n",
      "     |      ...             # split workload\n",
      "     |      ...             per_worker = int(math.ceil((self.end - self.start) / float(worker_info.num_workers)))\n",
      "     |      ...             worker_id = worker_info.id\n",
      "     |      ...             iter_start = self.start + worker_id * per_worker\n",
      "     |      ...             iter_end = min(iter_start + per_worker, self.end)\n",
      "     |      ...         return iter(range(iter_start, iter_end))\n",
      "     |      ...\n",
      "     |      >>> # should give same set of data as range(3, 7), i.e., [3, 4, 5, 6].\n",
      "     |      >>> ds = MyIterableDataset(start=3, end=7)\n",
      "     |  \n",
      "     |      >>> # Single-process loading\n",
      "     |      >>> print(list(torch.utils.data.DataLoader(ds, num_workers=0)))\n",
      "     |      [3, 4, 5, 6]\n",
      "     |  \n",
      "     |      >>> # Mult-process loading with two worker processes\n",
      "     |      >>> # Worker 0 fetched [3, 4].  Worker 1 fetched [5, 6].\n",
      "     |      >>> print(list(torch.utils.data.DataLoader(ds, num_workers=2)))\n",
      "     |      [3, 5, 4, 6]\n",
      "     |  \n",
      "     |      >>> # With even more workers\n",
      "     |      >>> print(list(torch.utils.data.DataLoader(ds, num_workers=20)))\n",
      "     |      [3, 4, 5, 6]\n",
      "     |  \n",
      "     |  Example 2: splitting workload across all workers using :attr:`worker_init_fn`::\n",
      "     |  \n",
      "     |      >>> class MyIterableDataset(torch.utils.data.IterableDataset):\n",
      "     |      ...     def __init__(self, start, end):\n",
      "     |      ...         super(MyIterableDataset).__init__()\n",
      "     |      ...         assert end > start, \"this example code only works with end >= start\"\n",
      "     |      ...         self.start = start\n",
      "     |      ...         self.end = end\n",
      "     |      ...\n",
      "     |      ...     def __iter__(self):\n",
      "     |      ...         return iter(range(self.start, self.end))\n",
      "     |      ...\n",
      "     |      >>> # should give same set of data as range(3, 7), i.e., [3, 4, 5, 6].\n",
      "     |      >>> ds = MyIterableDataset(start=3, end=7)\n",
      "     |  \n",
      "     |      >>> # Single-process loading\n",
      "     |      >>> print(list(torch.utils.data.DataLoader(ds, num_workers=0)))\n",
      "     |      [3, 4, 5, 6]\n",
      "     |      >>>\n",
      "     |      >>> # Directly doing multi-process loading yields duplicate data\n",
      "     |      >>> print(list(torch.utils.data.DataLoader(ds, num_workers=2)))\n",
      "     |      [3, 3, 4, 4, 5, 5, 6, 6]\n",
      "     |  \n",
      "     |      >>> # Define a `worker_init_fn` that configures each dataset copy differently\n",
      "     |      >>> def worker_init_fn(worker_id):\n",
      "     |      ...     worker_info = torch.utils.data.get_worker_info()\n",
      "     |      ...     dataset = worker_info.dataset  # the dataset copy in this worker process\n",
      "     |      ...     overall_start = dataset.start\n",
      "     |      ...     overall_end = dataset.end\n",
      "     |      ...     # configure the dataset to only process the split workload\n",
      "     |      ...     per_worker = int(math.ceil((overall_end - overall_start) / float(worker_info.num_workers)))\n",
      "     |      ...     worker_id = worker_info.id\n",
      "     |      ...     dataset.start = overall_start + worker_id * per_worker\n",
      "     |      ...     dataset.end = min(dataset.start + per_worker, overall_end)\n",
      "     |      ...\n",
      "     |  \n",
      "     |      >>> # Mult-process loading with the custom `worker_init_fn`\n",
      "     |      >>> # Worker 0 fetched [3, 4].  Worker 1 fetched [5, 6].\n",
      "     |      >>> print(list(torch.utils.data.DataLoader(ds, num_workers=2, worker_init_fn=worker_init_fn)))\n",
      "     |      [3, 5, 4, 6]\n",
      "     |  \n",
      "     |      >>> # With even more workers\n",
      "     |      >>> print(list(torch.utils.data.DataLoader(ds, num_workers=20, worker_init_fn=worker_init_fn)))\n",
      "     |      [3, 4, 5, 6]\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      IterableDataset\n",
      "     |      Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __add__(self, other: torch.utils.data.dataset.Dataset[+T_co])\n",
      "     |  \n",
      "     |  __iter__(self) -> Iterator[+T_co]\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __orig_bases__ = (torch.utils.data.dataset.Dataset[+T_co],)\n",
      "     |  \n",
      "     |  __parameters__ = (+T_co,)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Dataset:\n",
      "     |  \n",
      "     |  __getitem__(self, index) -> +T_co\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class Subset(Dataset)\n",
      "     |  Subset(dataset: torch.utils.data.dataset.Dataset[+T_co], indices: Sequence[int]) -> None\n",
      "     |  \n",
      "     |  Subset of a dataset at specified indices.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      dataset (Dataset): The whole Dataset\n",
      "     |      indices (sequence): Indices in the whole set selected for subset\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Subset\n",
      "     |      Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, idx)\n",
      "     |  \n",
      "     |  __init__(self, dataset: torch.utils.data.dataset.Dataset[+T_co], indices: Sequence[int]) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {'dataset': torch.utils.data.dataset.Dataset[+T_co],...\n",
      "     |  \n",
      "     |  __orig_bases__ = (torch.utils.data.dataset.Dataset[+T_co],)\n",
      "     |  \n",
      "     |  __parameters__ = (+T_co,)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class TensorDataset(Dataset)\n",
      "     |  TensorDataset(*tensors: torch.Tensor) -> None\n",
      "     |  \n",
      "     |  Dataset wrapping tensors.\n",
      "     |  \n",
      "     |  Each sample will be retrieved by indexing tensors along the first dimension.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      *tensors (Tensor): tensors that have the same size of the first dimension.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TensorDataset\n",
      "     |      Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index)\n",
      "     |  \n",
      "     |  __init__(self, *tensors: torch.Tensor) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {'tensors': typing.Tuple[torch.Tensor, ...]}\n",
      "     |  \n",
      "     |  __orig_bases__ = (torch.utils.data.dataset.Dataset[typing.Tuple[torch....\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "\n",
      "FUNCTIONS\n",
      "    random_split(dataset: torch.utils.data.dataset.Dataset[~T], lengths: Sequence[int], generator: Optional[torch._C.Generator] = <torch._C.Generator object at 0x000001842EB75490>) -> List[torch.utils.data.dataset.Subset[~T]]\n",
      "        Randomly split a dataset into non-overlapping new datasets of given lengths.\n",
      "        Optionally fix the generator for reproducible results, e.g.:\n",
      "        \n",
      "        >>> random_split(range(10), [3, 7], generator=torch.Generator().manual_seed(42))\n",
      "        \n",
      "        Args:\n",
      "            dataset (Dataset): Dataset to be split\n",
      "            lengths (sequence): lengths of splits to be produced\n",
      "            generator (Generator): Generator used for the random permutation.\n",
      "\n",
      "DATA\n",
      "    __all__ = ['Dataset', 'IterableDataset', 'TensorDataset', 'ConcatDatas...\n",
      "\n",
      "FILE\n",
      "    c:\\users\\david\\.conda\\envs\\pneuralevn\\lib\\site-packages\\torch\\utils\\data\\dataset.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from PIL import Image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "img_path = \"D:\\\\Python_project\\\\PNeural_project\\\\dataset\\\\train\\\\ants_image\\\\0013035.jpg\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "img = Image.open(img_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "img.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "dir_path = 'dataset/train/ants_image'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "img_path_list = os.listdir(dir_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "'1095476100_3906d8afde.jpg'"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path_list[2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "root_dir = \"dataset/train\"\n",
    "label_dir = \"ants_image\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "path = os.path.join(root_dir, label_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/train\\ants_image\n"
     ]
    }
   ],
   "source": [
    "print(path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "img_path = os.listdir(path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0013035.jpg', '1030023514_aad5c608f9.jpg', '1095476100_3906d8afde.jpg', '1099452230_d1949d3250.jpg', '116570827_e9c126745d.jpg', '1225872729_6f0856588f.jpg', '1262877379_64fcada201.jpg', '1269756697_0bce92cdab.jpg', '1286984635_5119e80de1.jpg', '132478121_2a430adea2.jpg', '1360291657_dc248c5eea.jpg', '1368913450_e146e2fb6d.jpg', '1473187633_63ccaacea6.jpg', '148715752_302c84f5a4.jpg', '1489674356_09d48dde0a.jpg', '149244013_c529578289.jpg', '150801003_3390b73135.jpg', '150801171_cd86f17ed8.jpg', '154124431_65460430f2.jpg', '162603798_40b51f1654.jpg', '1660097129_384bf54490.jpg', '167890289_dd5ba923f3.jpg', '1693954099_46d4c20605.jpg', '175998972.jpg', '178538489_bec7649292.jpg', '1804095607_0341701e1c.jpg', '1808777855_2a895621d7.jpg', '188552436_605cc9b36b.jpg', '1917341202_d00a7f9af5.jpg', '1924473702_daa9aacdbe.jpg', '196057951_63bf063b92.jpg', '196757565_326437f5fe.jpg', '201558278_fe4caecc76.jpg', '201790779_527f4c0168.jpg', '2019439677_2db655d361.jpg', '207947948_3ab29d7207.jpg', '20935278_9190345f6b.jpg', '224655713_3956f7d39a.jpg', '2265824718_2c96f485da.jpg', '2265825502_fff99cfd2d.jpg', '226951206_d6bf946504.jpg', '2278278459_6b99605e50.jpg', '2288450226_a6e96e8fdf.jpg', '2288481644_83ff7e4572.jpg', '2292213964_ca51ce4bef.jpg', '24335309_c5ea483bb8.jpg', '245647475_9523dfd13e.jpg', '255434217_1b2b3fe0a4.jpg', '258217966_d9d90d18d3.jpg', '275429470_b2d7d9290b.jpg', '28847243_e79fe052cd.jpg', '318052216_84dff3f98a.jpg', '334167043_cbd1adaeb9.jpg', '339670531_94b75ae47a.jpg', '342438950_a3da61deab.jpg', '36439863_0bec9f554f.jpg', '374435068_7eee412ec4.jpg', '382971067_0bfd33afe0.jpg', '384191229_5779cf591b.jpg', '386190770_672743c9a7.jpg', '392382602_1b7bed32fa.jpg', '403746349_71384f5b58.jpg', '408393566_b5b694119b.jpg', '424119020_6d57481dab.jpg', '424873399_47658a91fb.jpg', '450057712_771b3bfc91.jpg', '45472593_bfd624f8dc.jpg', '459694881_ac657d3187.jpg', '460372577_f2f6a8c9fc.jpg', '460874319_0a45ab4d05.jpg', '466430434_4000737de9.jpg', '470127037_513711fd21.jpg', '474806473_ca6caab245.jpg', '475961153_b8c13fd405.jpg', '484293231_e53cfc0c89.jpg', '49375974_e28ba6f17e.jpg', '506249802_207cd979b4.jpg', '506249836_717b73f540.jpg', '512164029_c0a66b8498.jpg', '512863248_43c8ce579b.jpg', '518773929_734dbc5ff4.jpg', '522163566_fec115ca66.jpg', '522415432_2218f34bf8.jpg', '531979952_bde12b3bc0.jpg', '533848102_70a85ad6dd.jpg', '535522953_308353a07c.jpg', '540889389_48bb588b21.jpg', '541630764_dbd285d63c.jpg', '543417860_b14237f569.jpg', '560966032_988f4d7bc4.jpg', '5650366_e22b7e1065.jpg', '6240329_72c01e663e.jpg', '6240338_93729615ec.jpg', '649026570_e58656104b.jpg', '662541407_ff8db781e7.jpg', '67270775_e9fdf77e9d.jpg', '6743948_2b8c096dda.jpg', '684133190_35b62c0c1d.jpg', '69639610_95e0de17aa.jpg', '707895295_009cf23188.jpg', '7759525_1363d24e88.jpg', '795000156_a9900a4a71.jpg', '822537660_caf4ba5514.jpg', '82852639_52b7f7f5e3.jpg', '841049277_b28e58ad05.jpg', '886401651_f878e888cd.jpg', '892108839_f1aad4ca46.jpg', '938946700_ca1c669085.jpg', '957233405_25c1d1187b.jpg', '9715481_b3cb4114ff.jpg', '998118368_6ac1d91f81.jpg', 'ant photos.jpg', 'Ant_1.jpg', 'army-ants-red-picture.jpg', 'formica.jpeg', 'hormiga_co_por.jpg', 'imageNotFound.gif', 'kurokusa.jpg', 'MehdiabadiAnt2_600.jpg', 'Nepenthes_rafflesiana_ant.jpg', 'swiss-army-ant.jpg', 'termite-vs-ant.jpg', 'trap-jaw-ant-insect-bg.jpg', 'VietnameseAntMimicSpider.jpg']\n"
     ]
    }
   ],
   "source": [
    "print(img_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "idx = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "img_item_path = os.path.join(root_dir,label_dir,img_path[idx])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/train\\ants_image\\0013035.jpg\n"
     ]
    }
   ],
   "source": [
    "print(img_item_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "img2 = Image.open(img_item_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "img2.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class Mydata(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, label_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.path = os.path.join(self.root_dir, self.label_dir)\n",
    "        self.img_path = os.listdir(self.path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.img_path[idx]\n",
    "        img_item_path = os.path.join(self.root_dir, self.label_dir, img_name)\n",
    "        img = Image.open(img_item_path)\n",
    "        label = self.label_dir\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "root_dir = \"dataset/train\"\n",
    "ants_label_dir = \"ants_image\"\n",
    "bees_label_dir = \"bees_image\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "ants_dataset = Mydata(root_dir, ants_label_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "ants_dataset = Mydata(root_dir, ants_label_dir)\n",
    "bees_dataset = Mydata(root_dir, bees_label_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "img1, label1 = ants_dataset[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "img1.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ants_image\n"
     ]
    }
   ],
   "source": [
    "print(label1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "img2, label2 = bees_dataset[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "img2.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bees_image\n"
     ]
    }
   ],
   "source": [
    "print(label2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "train_dataset = ants_dataset + bees_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "245"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "124"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ants_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "121"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bees_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "img3, label3 = train_dataset[123]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "img3.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "img4, label4 = train_dataset[124]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "img4.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"logs\")\n",
    "\n",
    "# writer.add_image()\n",
    "\n",
    "# y = x\n",
    "for i in range(100):\n",
    "    writer.add_scalar('y=3x',3*i , i)\n",
    "# writer.add_scalar()\n",
    "\n",
    "writer.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "tensorboard --logdir=logs #RUN IN TERMINAL"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "img = Image.open('dataset/train/ants_image/0013035.jpg')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.JpegImagePlugin.JpegImageFile'>\n"
     ]
    }
   ],
   "source": [
    "print(type(img))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "img_array = np.array(img)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(img_array))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 80 151 233]\n",
      "  [ 80 151 233]\n",
      "  [ 80 151 233]\n",
      "  ...\n",
      "  [ 81 152 234]\n",
      "  [ 79 150 232]\n",
      "  [ 76 147 229]]\n",
      "\n",
      " [[ 81 152 234]\n",
      "  [ 81 152 234]\n",
      "  [ 81 152 234]\n",
      "  ...\n",
      "  [ 81 152 234]\n",
      "  [ 79 150 232]\n",
      "  [ 76 147 229]]\n",
      "\n",
      " [[ 82 153 235]\n",
      "  [ 82 153 235]\n",
      "  [ 82 153 235]\n",
      "  ...\n",
      "  [ 80 151 233]\n",
      "  [ 79 150 232]\n",
      "  [ 77 148 230]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 87 160 237]\n",
      "  [ 87 160 237]\n",
      "  [ 86 159 236]\n",
      "  ...\n",
      "  [ 44  92 141]\n",
      "  [ 95 158 235]\n",
      "  [ 90 157 228]]\n",
      "\n",
      " [[ 87 160 237]\n",
      "  [ 87 160 237]\n",
      "  [ 86 159 236]\n",
      "  ...\n",
      "  [ 84 147 226]\n",
      "  [ 90 160 255]\n",
      "  [ 84 152 233]]\n",
      "\n",
      " [[ 87 160 237]\n",
      "  [ 87 160 237]\n",
      "  [ 86 159 236]\n",
      "  ...\n",
      "  [ 79 160 242]\n",
      "  [ 78 159 250]\n",
      "  [ 84 161 233]]]\n"
     ]
    }
   ],
   "source": [
    "print(img_array)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 500, 3)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "writer = SummaryWriter(\"logs\")\n",
    "img_path = 'dataset/train/bees_image/16838648_415acd9e3f.jpg'\n",
    "img_PIL = Image.open(img_path)\n",
    "img_array = np.array(img_PIL)\n",
    "print(img_array.shape)\n",
    "\n",
    "writer.add_image('test', img_array, 2, dataformats='HWC')\n",
    "\n",
    "\n",
    "writer.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3137, 0.3137, 0.3137,  ..., 0.3176, 0.3098, 0.2980],\n",
      "         [0.3176, 0.3176, 0.3176,  ..., 0.3176, 0.3098, 0.2980],\n",
      "         [0.3216, 0.3216, 0.3216,  ..., 0.3137, 0.3098, 0.3020],\n",
      "         ...,\n",
      "         [0.3412, 0.3412, 0.3373,  ..., 0.1725, 0.3725, 0.3529],\n",
      "         [0.3412, 0.3412, 0.3373,  ..., 0.3294, 0.3529, 0.3294],\n",
      "         [0.3412, 0.3412, 0.3373,  ..., 0.3098, 0.3059, 0.3294]],\n",
      "\n",
      "        [[0.5922, 0.5922, 0.5922,  ..., 0.5961, 0.5882, 0.5765],\n",
      "         [0.5961, 0.5961, 0.5961,  ..., 0.5961, 0.5882, 0.5765],\n",
      "         [0.6000, 0.6000, 0.6000,  ..., 0.5922, 0.5882, 0.5804],\n",
      "         ...,\n",
      "         [0.6275, 0.6275, 0.6235,  ..., 0.3608, 0.6196, 0.6157],\n",
      "         [0.6275, 0.6275, 0.6235,  ..., 0.5765, 0.6275, 0.5961],\n",
      "         [0.6275, 0.6275, 0.6235,  ..., 0.6275, 0.6235, 0.6314]],\n",
      "\n",
      "        [[0.9137, 0.9137, 0.9137,  ..., 0.9176, 0.9098, 0.8980],\n",
      "         [0.9176, 0.9176, 0.9176,  ..., 0.9176, 0.9098, 0.8980],\n",
      "         [0.9216, 0.9216, 0.9216,  ..., 0.9137, 0.9098, 0.9020],\n",
      "         ...,\n",
      "         [0.9294, 0.9294, 0.9255,  ..., 0.5529, 0.9216, 0.8941],\n",
      "         [0.9294, 0.9294, 0.9255,  ..., 0.8863, 1.0000, 0.9137],\n",
      "         [0.9294, 0.9294, 0.9255,  ..., 0.9490, 0.9804, 0.9137]]])\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Usage of Python --> Totensor data type\n",
    "# From transform.Totensor，解决两个问题\n",
    "# 2， Tensor 数据类型的特点，以及为什么需要这个类型的数据。\n",
    "\n",
    "\n",
    "img_path = 'D:\\\\Python_project\\\\PNeural_project\\\\dataset\\\\train\\\\ants_image\\\\0013035.jpg'\n",
    "# 1. Transform 的使用方法；\n",
    "img = Image.open(img_path)\n",
    "tensor_trans = transforms.ToTensor()        # 函数重定向声明\n",
    "tensor_img = tensor_trans(img)\n",
    "print(tensor_img)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import cv2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "cv_img = cv2.imread(img_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(cv_img))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "可以看到 TOTENSOR 输入的数据类型同时支持 CV2 和 PIL 读入。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}